# ğŸ¤š YOLO11 Pose æ‰‹åŠ¿å…³é”®ç‚¹æ£€æµ‹é¡¹ç›®

åŸºäºYOLO11çš„æ‰‹åŠ¿å…³é”®ç‚¹æ£€æµ‹æ•°æ®é›†æ„å»ºå’Œè®­ç»ƒå·¥å…·ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„å·¥å…·é“¾ï¼Œç”¨äºå°†LabelMeæ ¼å¼çš„æ‰‹åŠ¿å…³é”®ç‚¹æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºYOLO11 Poseæ ¼å¼ï¼Œå¹¶è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ã€‚

### ç‰¹æ€§

- âœ… è‡ªåŠ¨è½¬æ¢LabelMeæ ‡æ³¨ä¸ºYOLOæ ¼å¼
- âœ… æ™ºèƒ½æ•°æ®é›†åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰
- âœ… å®Œæ•´çš„è®­ç»ƒè„šæœ¬å’Œé…ç½®
- âœ… é¢„æµ‹å’Œå¯è§†åŒ–å·¥å…·
- âœ… æ•°æ®é›†éªŒè¯å·¥å…·
- âœ… æ”¯æŒå¤šç§æ¨¡å‹å¯¼å‡ºæ ¼å¼

## ğŸ“Š æ•°æ®é›†ç»Ÿè®¡

- **æ€»æ ·æœ¬æ•°**: 2722
- **è®­ç»ƒé›†**: 1902 (70%)
- **éªŒè¯é›†**: 540 (20%)
- **æµ‹è¯•é›†**: 280 (10%)
- **å…³é”®ç‚¹æ•°**: 3ä¸ª/æ‰‹åŠ¿
- **ç±»åˆ«æ•°**: 9ä¸ªæ‰‹åŠ¿ç±»åˆ«

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install ultralytics pyyaml opencv-python numpy

# æˆ–ä½¿ç”¨requirements.txt
pip install -r requirements.txt
```

### 2. æ„å»ºæ•°æ®é›†

```bash
python build_yolo_dataset.py
```

è¿™å°†åˆ›å»º `yolo_hand_pose_dataset/` ç›®å½•ï¼ŒåŒ…å«YOLOæ ¼å¼çš„è®­ç»ƒæ•°æ®ã€‚

### 3. éªŒè¯æ•°æ®é›†

```bash
python verify_dataset.py
```

### 4. è®­ç»ƒæ¨¡å‹

```bash
```bash
# æ ‡å‡†è®­ç»ƒ (YOLO11s)
python train_yolo_detection.py

# æ”¹è¿›ç‰ˆè®­ç»ƒ (æé«˜ä¸‰è§’ç‚¹å¬å›ç‡)
# ä½¿ç”¨YOLO11m + ä¼˜åŒ–å¢å¼ºå‚æ•°
python train_yolo_detection_improved.py
```

### 5. é¢„æµ‹

```bash
# å•å¼ å›¾ç‰‡
python predict_and_visualize.py --model runs/pose/hand_pose_yolo11/weights/best.pt --source image.jpg

# æ‰¹é‡é¢„æµ‹
python predict_and_visualize.py --model runs/pose/hand_pose_yolo11/weights/best.pt --source images/ --batch
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ build_yolo_dataset.py          # æ•°æ®é›†æ„å»ºè„šæœ¬
â”œâ”€â”€ train_yolo_detection.py        # è®­ç»ƒè„šæœ¬ (YOLO11s)
â”œâ”€â”€ train_yolo_detection_improved.py # è®­ç»ƒè„šæœ¬ (æ”¹è¿›ç‰ˆ - æé«˜å¬å›ç‡)
â”œâ”€â”€ predict_and_visualize.py       # é¢„æµ‹å’Œå¯è§†åŒ–
â”œâ”€â”€ verify_dataset.py              # æ•°æ®é›†éªŒè¯
â”œâ”€â”€ README.md                      # æœ¬æ–‡ä»¶
â”œâ”€â”€ README_dataset.md              # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ QUICKSTART.md                  # å¿«é€Ÿå¼€å§‹æŒ‡å—
â”œâ”€â”€ é¡¹ç›®æ€»ç»“.md                    # é¡¹ç›®æ€»ç»“
â”œâ”€â”€ 25923æ‰“æ ‡æ–‡ä»¶/                 # åŸå§‹æ ‡æ³¨æ•°æ®
â”‚   â”œâ”€â”€ æ°´/
â”‚   â”œâ”€â”€ é‡‘/
â”‚   â”œâ”€â”€ åœ°/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ yolo_hand_pose_dataset/        # YOLOæ ¼å¼æ•°æ®é›†
â”‚   â”œâ”€â”€ data.yaml
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ runs/                          # è®­ç»ƒè¾“å‡º
    â””â”€â”€ pose/
        â””â”€â”€ hand_pose_yolo11/
            â””â”€â”€ weights/
                â”œâ”€â”€ best.pt
                â””â”€â”€ last.pt
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### Python API

```python
from ultralytics import YOLO

# è®­ç»ƒ
model = YOLO('yolo11n-pose.pt')
model.train(data='yolo_hand_pose_dataset/data.yaml', epochs=100)

# é¢„æµ‹
results = model.predict('image.jpg')

# è·å–å…³é”®ç‚¹
for result in results:
    keypoints = result.keypoints.xy  # å…³é”®ç‚¹åæ ‡
    boxes = result.boxes.xyxy        # è¾¹ç•Œæ¡†
    confs = result.boxes.conf        # ç½®ä¿¡åº¦
```

### å‘½ä»¤è¡Œ

```bash
# è®­ç»ƒ
yolo pose train data=yolo_hand_pose_dataset/data.yaml model=yolo11n-pose.pt epochs=100

# é¢„æµ‹
yolo pose predict model=runs/pose/hand_pose_yolo11/weights/best.pt source=image.jpg

# éªŒè¯
yolo pose val model=runs/pose/hand_pose_yolo11/weights/best.pt data=yolo_hand_pose_dataset/data.yaml
```

## ğŸ“š æ–‡æ¡£

- [README_dataset.md](README_dataset.md) - è¯¦ç»†çš„æ•°æ®é›†è¯´æ˜å’Œä½¿ç”¨æŒ‡å—
- [QUICKSTART.md](QUICKSTART.md) - å¿«é€Ÿå¼€å§‹æŒ‡å—
- [é¡¹ç›®æ€»ç»“.md](é¡¹ç›®æ€»ç»“.md) - é¡¹ç›®æ€»ç»“å’ŒæŠ€æœ¯ç»†èŠ‚

## ğŸ”§ é…ç½®å‚æ•°

### æ•°æ®é›†æ„å»º

ç¼–è¾‘ `build_yolo_dataset.py`:

```python
TRAIN_RATIO = 0.7           # è®­ç»ƒé›†æ¯”ä¾‹
VAL_RATIO = 0.2             # éªŒè¯é›†æ¯”ä¾‹
TEST_RATIO = 0.1            # æµ‹è¯•é›†æ¯”ä¾‹
SAMPLES_PER_CATEGORY = None # æ¯ç±»æ ·æœ¬æ•°é™åˆ¶
```

### è®­ç»ƒå‚æ•°

ç¼–è¾‘ `train_yolo_detection.py` æˆ–ç›´æ¥ä¼ å‚:

```python
model.train(
    data='yolo_hand_pose_dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    lr0=0.01,
    device=0,  # GPU ID
)
```

## ğŸ¨ å¯è§†åŒ–

è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨ç”Ÿæˆ:
- è®­ç»ƒæ›²çº¿ (`results.png`)
- æ··æ·†çŸ©é˜µ (`confusion_matrix.png`)
- éªŒè¯é›†é¢„æµ‹ç¤ºä¾‹ (`val_batch*.jpg`)

## ğŸ“¦ æ¨¡å‹å¯¼å‡º

```python
model = YOLO('runs/pose/hand_pose_yolo11/weights/best.pt')

# ONNX
model.export(format='onnx')

# TorchScript
model.export(format='torchscript')

# CoreML (iOS)
model.export(format='coreml')

# TFLite (Android)
model.export(format='tflite')
```

## ğŸ” æ•°æ®é›†éªŒè¯ç»“æœ

```
âœ“ ç›®å½•ç»“æ„å®Œæ•´
âœ“ é…ç½®æ–‡ä»¶æ­£ç¡®
âœ“ å›¾ç‰‡å’Œæ ‡æ³¨æ•°é‡åŒ¹é…
âœ“ æ ‡æ³¨æ ¼å¼æ­£ç¡®
âœ“ å›¾ç‰‡å¯è¯»
âœ“ æ•°å€¼èŒƒå›´æœ‰æ•ˆ
```

## ğŸ’¡ æç¤º

1. **GPUè®­ç»ƒ**: ç¡®ä¿å®‰è£…äº†CUDAå’Œå¯¹åº”ç‰ˆæœ¬çš„PyTorch
2. **å†…å­˜ä¸è¶³**: å‡å° `batch` å‚æ•°æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
3. **æ•°æ®ä¸å¹³è¡¡**: ä½¿ç”¨ `SAMPLES_PER_CATEGORY` é™åˆ¶æ¯ç±»æ ·æœ¬æ•°
4. **æé«˜å‡†ç¡®ç‡**: å¢åŠ è®­ç»ƒè½®æ•°ã€ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ã€è°ƒæ•´æ•°æ®å¢å¼º

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

| æ¨¡å‹ | å¤§å° | mAP50 | é€Ÿåº¦ (ms) | æ¨èåœºæ™¯ |
|------|------|-------|-----------|----------|
| yolo11n-pose | 3.3M | - | ~2 | å®æ—¶åº”ç”¨ |
| yolo11s-pose | 11.6M | - | ~3 | å¹³è¡¡ |
| yolo11m-pose | 26.4M | - | ~5 | é«˜å‡†ç¡®ç‡ |
| yolo11l-pose | 58.9M | - | ~8 | ç¦»çº¿å¤„ç† |
| yolo11x-pose | 78.9M | - | ~12 | æœ€é«˜å‡†ç¡®ç‡ |

*æ³¨: å®é™…æ€§èƒ½éœ€è¦åœ¨ä½ çš„æ•°æ®é›†ä¸Šè®­ç»ƒåæµ‹è¯•*

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ™ è‡´è°¢

- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [LabelMe](https://github.com/wkentaro/labelme)

---

## ğŸ§  å¤šæ¨¡æ€åˆ†ç±» (B-PACO Heatmap Early Fusion)

æœ¬é¡¹ç›®è¿˜åŒ…å«äº†ä¸€ä¸ªé«˜çº§çš„å¤šæ¨¡æ€åˆ†ç±»æ¨¡å‹ï¼Œç»“åˆäº†å…³é”®ç‚¹æ£€æµ‹ä¿¡æ¯å’ŒåŸå§‹å›¾åƒï¼Œä½¿ç”¨ B-PACO (Balanced Prototype and Contrastive Learning) ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚

### æ ¸å¿ƒæ€æƒ³
- **Early Fusion (å‰èåˆ)**: å°† YOLO æ£€æµ‹åˆ°çš„å…³é”®ç‚¹è½¬æ¢ä¸ºé«˜æ–¯çƒ­åŠ›å›¾ (Heatmap)ï¼Œä½œä¸ºå›¾åƒçš„ç¬¬ä¸‰ä¸ªé€šé“ (Gray, Gray, Heatmap)ã€‚
- **ResNet Backbone**: ç›´æ¥åˆ©ç”¨ ImageNet é¢„è®­ç»ƒçš„ ResNet æå–ç©ºé—´ç‰¹å¾ï¼Œæ— éœ€å¤æ‚çš„ Transformerã€‚
- **ç»Ÿè®¡ç‰¹å¾èåˆ**: å°†æ˜¾å¼çš„ç»Ÿè®¡ç‰¹å¾ (å¦‚ `is_left_hand`, `num_keypoints`) åœ¨å…¨è¿æ¥å±‚å‰èåˆã€‚
- **B-PACO Loss**: ç»“åˆå¯¹æ¯”å­¦ä¹ æŸå¤± (Contrastive Loss) å’Œ äº¤å‰ç†µæŸå¤±ï¼Œè§£å†³é•¿å°¾åˆ†å¸ƒå’Œç±»å†…å·®å¼‚å¤§é—®é¢˜ã€‚

### è®­ç»ƒ

```bash
# å•æ¬¡è®­ç»ƒ
python multimodal_classification/train_bpaco_heatmap.py \
    --dataset classification_dataset \
    --keypoint-features keypoint_features.csv \
    --backbone resnet18 \
    --epochs 100 \
    --output-dir results/bpaco_heatmap
```

### è‡ªåŠ¨è°ƒå‚ (Auto Tuning)

ä½¿ç”¨æä¾›çš„è„šæœ¬è‡ªåŠ¨æœç´¢æœ€ä½³è¶…å‚æ•° (Sigma, LR, Beta):

```bash
bash multimodal_classification/run_heatmap_tuning.sh
```

ç»“æœå°†ä¿å­˜åœ¨ `results/bpaco_tuning/` ç›®å½•ä¸‹ã€‚

### å…³é”®æ–‡ä»¶
- `multimodal_classification/train_bpaco_heatmap.py`: ä¸»è®­ç»ƒè„šæœ¬
- `multimodal_classification/run_heatmap_tuning.sh`: è‡ªåŠ¨è°ƒå‚è„šæœ¬
- `keypoint_features.csv`: é¢„æå–çš„å…³é”®ç‚¹ç»Ÿè®¡ç‰¹å¾

---

**å¼€å§‹è®­ç»ƒä½ çš„æ‰‹åŠ¿æ£€æµ‹æ¨¡å‹å§ï¼** ğŸš€

