import os
import random
import json
from pathlib import Path
from typing import Tuple, List

import numpy as np
import cv2
from PIL import Image
from datetime import datetime

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as T
import torchvision.models as models

from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score
import matplotlib.pyplot as plt

# =========================================================
# å½¢æ€å­¦å¢å¼ºå˜æ¢ï¼ˆå¼€è¿ç®—å–å Ã— äºŒå€¼åŒ–ï¼‰
# =========================================================

class FingerprintMorphologyTransform:
    """
    å°†å•é€šé“ç°åº¦æŒ‡çº¹å¼ é‡åšå½¢æ€å­¦å¢å¼ºï¼Œå¤ç°ï¼š
        é¡¶å¸½ -> å±€éƒ¨é˜ˆå€¼äºŒå€¼åŒ– -> é»‘å¸½ -> é»‘å¸½å¼€è¿ç®— -> å–å Ã— äºŒå€¼å›¾

    è¾“å…¥:  x  shape (1, H, W), å€¼åŸŸ [0,1]
    è¾“å‡º:  åŒ shape, å¢å¼ºåçš„ 0~1 æµ®ç‚¹å¼ é‡
    """

    def __init__(
        self,
        kernel_tophat: int = 15,
        kernel_blackhat: int = 25,
        kernel_open: int = 3,
        block_size: int = 21,
        C: int = 8,
    ) -> None:
        self.kernel_tophat = kernel_tophat
        self.kernel_blackhat = kernel_blackhat
        self.kernel_open = kernel_open
        self.block_size = block_size
        self.C = C

    def __call__(self, x: torch.Tensor) -> torch.Tensor:
        # æœŸæœ›è¾“å…¥æ˜¯ (1, H, W) çš„ç°åº¦å›¾ï¼Œå€¼åŸŸ [0,1]
        if x.dim() != 3 or x.size(0) != 1:
            raise ValueError(
                f"FingerprintMorphologyTransform æœŸæœ›è¾“å…¥ä¸º (1,H,W)ï¼Œå¾—åˆ° {tuple(x.shape)}"
            )

        # è½¬ä¸º uint8 å›¾åƒ
        img = x.squeeze(0).cpu().numpy()
        img_u8 = np.clip(img * 255.0, 0, 255).astype(np.uint8)

        # 1) é¡¶å¸½å»èƒŒæ™¯
        k_top = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE, (self.kernel_tophat, self.kernel_tophat)
        )
        tophat = cv2.morphologyEx(img_u8, cv2.MORPH_TOPHAT, k_top)
        if tophat.max() > 0:
            tophat_enh = cv2.normalize(tophat, None, 0, 255, cv2.NORM_MINMAX)
        else:
            tophat_enh = tophat

        # 2) è‡ªé€‚åº”é˜ˆå€¼ -> äºŒå€¼æŒ‡çº¹
        binary = cv2.adaptiveThreshold(
            tophat_enh,
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            self.block_size,
            self.C,
        )

        # 3) é»‘å¸½æå–æš— ridge é—´éš™
        k_bh = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE, (self.kernel_blackhat, self.kernel_blackhat)
        )
        blackhat = cv2.morphologyEx(img_u8, cv2.MORPH_BLACKHAT, k_bh)
        if blackhat.max() > 0:
            blackhat = cv2.normalize(blackhat, None, 0, 255, cv2.NORM_MINMAX)

        blackhat_bin = cv2.adaptiveThreshold(
            blackhat,
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            self.block_size,
            self.C,
        )

        # 4) é»‘å¸½ç»“æœåšå¼€è¿ç®—ï¼Œå»é™¤å­¤ç«‹å™ªå£°
        k_open = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE, (self.kernel_open, self.kernel_open)
        )
        blackhat_open = cv2.morphologyEx(
            blackhat_bin, cv2.MORPH_OPEN, k_open, iterations=1
        )

        # 5) å¼€è¿ç®—ç»“æœå–åï¼Œä¸åŸäºŒå€¼å›¾ç›¸ä¹˜
        opening_inv = cv2.bitwise_not(blackhat_open)
        result = cv2.bitwise_and(opening_inv, binary)

        # å›åˆ° (1,H,W) çš„ float tensorï¼ŒèŒƒå›´ 0~1
        result_f = torch.from_numpy(result.astype(np.float32) / 255.0)
        if result_f.dim() == 2:
            result_f = result_f.unsqueeze(0)
        return result_f


# =========================================================
# è®¾ç½®éšæœºç§å­ï¼Œä¿è¯è®­ç»ƒå¯å¤ç°
# =========================================================
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

# è‡ªåŠ¨æ£€æµ‹ GPU æˆ– CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class FingerprintDataset(Dataset):
    """
    æ¯æ¬¡è¿”å›ï¼š
        - v1ï¼šç¬¬ä¸€ä»½å¢å¼ºè§†å›¾ï¼ˆç”± aug1 ç”Ÿæˆï¼‰
        - v2ï¼šç¬¬äºŒä»½å¢å¼ºè§†å›¾ï¼ˆç”± aug2 ç”Ÿæˆï¼‰
        - labelï¼šç±»åˆ«æ ‡ç­¾

    ç‰¹ç‚¹ï¼š
    1. æ”¯æŒå½¢æ€å­¦å¢å¼ºï¼ˆé»‘å¸½å¼€è¿ç®—å–å Ã— äºŒå€¼åŒ–ï¼‰
    2. æ”¯æŒè‡ªåŠ¨åˆ’åˆ† train/val
    3. è¾“å‡ºç»è¿‡æ ‡å‡†åŒ–çš„ 3 é€šé“å›¾åƒï¼ˆé€‚é… ImageNet é¢„è®­ç»ƒ backboneï¼‰
    """

    def __init__(self, root: str, split: str = "train", image_size: int = 224):
        super().__init__()

        root = Path(root)
        assert root.exists(), f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {root}"

        # ç±»åˆ«é¡ºåºå›ºå®šï¼ˆç²—ç²’åº¦ 3 ç±»ï¼‰
        classes = [d.name for d in root.iterdir() if d.is_dir()]
        classes.sort()
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}
        self.num_classes = len(classes)  # æ·»åŠ num_classeså±æ€§

        # è¯»å–å…¨éƒ¨æ ·æœ¬è·¯å¾„ - æ”¯æŒå­æ–‡ä»¶å¤¹ç»“æ„
        self.samples: List[Tuple[str, int]] = []
        for cls_name in classes:
            cls_path = root / cls_name
            if not cls_path.exists():
                continue

            # éå†ç±»åˆ«ä¸‹çš„å­æ–‡ä»¶å¤¹
            for subfolder in cls_path.iterdir():
                if not subfolder.is_dir():
                    # å¦‚æœä¸æ˜¯ç›®å½•ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒæ–‡ä»¶ï¼ˆç›´æ¥æ”¾åœ¨ç±»åˆ«æ–‡ä»¶å¤¹ä¸‹çš„æƒ…å†µï¼‰
                    if subfolder.suffix.lower() in [ ".jpg", ".jpeg", ".png", ]:
                        self.samples.append(
                            (str(subfolder), self.class_to_idx[cls_name])
                        )
                    continue

                # éå†å­æ–‡ä»¶å¤¹ä¸‹çš„å›¾åƒæ–‡ä»¶
                for img_file in subfolder.iterdir():
                    if img_file.suffix.lower() in [ ".jpg", ".jpeg", ".png", ]:
                        self.samples.append(
                            (str(img_file), self.class_to_idx[cls_name])
                        )

        # è¿›è¡Œ train/val åˆ’åˆ†
        train_files, val_files = train_test_split(
            self.samples,
            test_size=0.15,
            random_state=SEED,
            stratify=[lbl for _, lbl in self.samples],
        )

        self.samples = train_files if split == "train" else val_files

        # å½’ä¸€åŒ–ï¼ˆè¿™é‡Œç”¨ç®€å• 0.5/0.5ï¼ŒæŒ‡çº¹æ˜¯é»‘ç™½å›¾ï¼Œå¤ªè®²ç©¶ ImageNet å‡å€¼åè€Œä¸å¥½ï¼‰
        self.normalize = T.Normalize(
            mean=[0.5, 0.5, 0.5],
            std=[0.5, 0.5, 0.5],
        )

        # å½¢æ€å­¦æ»¤æ³¢å˜æ¢å®ä¾‹ï¼ˆå¼€è¿ç®—å–å Ã— äºŒå€¼åŒ–ï¼‰
        self.morph = FingerprintMorphologyTransform()

        # ä¸¤ä¸ªè§†å›¾çš„å¢å¼ºç­–ç•¥
        # v1ï¼šå¸¦éšæœºæ¨¡ç³Š/ç¿»è½¬ + éšæœºå½¢æ€å­¦å¢å¼ºï¼Œç”¨äºå­¦ä¹ é²æ£’ç‰¹å¾
        self.aug1 = T.Compose(
            [
                T.Resize((image_size, image_size)),
                T.RandomHorizontalFlip(),
                T.RandomApply([T.GaussianBlur(3)], p=0.2),
                T.ToTensor(),  # -> (1, H, W) ç°åº¦
                T.RandomApply([self.morph], p=0.7),
                T.Lambda(lambda x: x.repeat(3, 1, 1)),  # ç°åº¦å¤åˆ¶ä¸º 3 é€šé“
                self.normalize,
            ]
        )

        # v2ï¼šå§‹ç»ˆä½¿ç”¨å½¢æ€å­¦å¢å¼ºï¼Œå¾—åˆ°â€œå¹²å‡€â€çš„ç»“æ„è§†å›¾
        self.aug2 = T.Compose(
            [
                T.Resize((image_size, image_size)),
                T.ToTensor(),
                self.morph,
                T.Lambda(lambda x: x.repeat(3, 1, 1)),
                self.normalize,
            ]
        )

    # è¿”å›æ ·æœ¬æ•°é‡
    def __len__(self):
        return len(self.samples)

    # è¿”å›å¢å¼ºåçš„ v1ã€v2 å’Œ æ ‡ç­¾
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]

        # æ‰“å¼€å›¾åƒï¼ˆç°åº¦æŒ‡çº¹å›¾ï¼ŒæŒ‰ç°åº¦è¯»å–ï¼‰
        img = Image.open(img_path).convert("L")

        # ä¸¤ä»½ä¸åŒå¢å¼ºè§†å›¾
        v1 = self.aug1(img)
        v2 = self.aug2(img)

        return v1, v2, torch.tensor(label, dtype=torch.long)


class ALWAnnotationsDataset(Dataset):
    """
    ä½¿ç”¨ annotations/*.json ä¸­çš„ f_code é¦–å­—æ¯ (A/L/W) ä½œä¸ºä¸‰åˆ†ç±»æ ‡ç­¾ï¼Œ
    å›¾åƒè·¯å¾„æ¥è‡ªåŒä¸€æ ‡æ³¨çš„ image_filenameï¼Œå›¾åƒä½äº images/ ç›®å½•ã€‚
    """

    def __init__(self, images_dir: str = "images", annotations_dir: str = "annotations", image_size: int = 224):
        super().__init__()
        self.images_dir = Path(images_dir)
        self.annotations_dir = Path(annotations_dir)
        assert self.images_dir.exists(), f"åŸå§‹å›¾åƒç›®å½•ä¸å­˜åœ¨: {self.images_dir}"
        assert self.annotations_dir.exists(), f"æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {self.annotations_dir}"

        label_map = {"A": 0, "L": 1, "W": 2}
        self.samples: List[Tuple[str, int]] = []

        for ann_file in sorted(self.annotations_dir.glob("*.json")):
            try:
                with open(ann_file, "r", encoding="utf-8") as f:
                    ann_data = json.load(f)
            except Exception:
                continue

            f_code = ann_data.get("f_code", "")
            if not f_code:
                continue
            family = f_code[0].upper()
            if family not in label_map:
                continue

            image_filename = ann_data.get("image_filename")
            if not image_filename:
                continue
            image_path = self.images_dir / image_filename
            if not image_path.exists():
                continue

            self.samples.append((str(image_path), label_map[family]))

        self.num_classes = len(label_map)
        if len(self.samples) == 0:
            raise ValueError("æœªæ‰¾åˆ°å¯ç”¨çš„ A/L/W æ ·æœ¬ï¼Œè¯·æ£€æŸ¥ images/ ä¸ annotations/ æ˜¯å¦åŒ¹é…ã€‚")

        self.normalize = T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        self.morph = FingerprintMorphologyTransform()

        self.aug1 = T.Compose(
            [
                T.Resize((image_size, image_size)),
                T.RandomHorizontalFlip(),
                T.RandomApply([T.GaussianBlur(3)], p=0.2),
                T.ToTensor(),
                T.RandomApply([self.morph], p=0.7),
                T.Lambda(lambda x: x.repeat(3, 1, 1)),
                self.normalize,
            ]
        )
        self.aug2 = T.Compose(
            [
                T.Resize((image_size, image_size)),
                T.ToTensor(),
                self.morph,
                T.Lambda(lambda x: x.repeat(3, 1, 1)),
                self.normalize,
            ]
        )

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("L")
        v1 = self.aug1(img)
        v2 = self.aug2(img)
        return v1, v2, torch.tensor(label, dtype=torch.long)


# =========================================================
# æ¨¡å— 2ï¼šç¼–ç å™¨ BpacoEncoder + åˆ†ç±»å™¨æƒé‡æ˜ å°„å™¨ (C2 Mapper)
# =========================================================


class BpacoEncoder(nn.Module):
    """
    BpacoEncoderï¼ˆç¼–ç å™¨ backboneï¼‰

    è¾“å‡ºï¼š
        - featï¼šç”¨äºåˆ†ç±»çš„ç‰¹å¾ï¼ˆbackbone æœ€åä¸€å±‚æ± åŒ–ç»“æœï¼‰
        - z   ï¼šæŠ•å½±å¤´è¾“å‡ºçš„ç‰¹å¾ï¼ˆå½’ä¸€åŒ–åç”¨äºå¯¹æ¯”å­¦ä¹ ï¼‰
    """

    def __init__(self, backbone="resnet34", proj_dim=128, pretrained=True):
        super().__init__()

        # ---------------------
        # é€‰æ‹© backbone
        # ---------------------
        if backbone == "resnet18":
            self.backbone = models.resnet18(
                weights=models.ResNet18_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.fc.in_features
            modules = list(self.backbone.children())[:-1]
            self.encoder = nn.Sequential(
                *modules
            )  # è¾“å‡ºå°ºå¯¸ (B, feat_dim, 1, 1)
        elif backbone == "resnet34":
            self.backbone = models.resnet34(
                weights=models.ResNet34_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.fc.in_features
            modules = list(self.backbone.children())[:-1]
            self.encoder = nn.Sequential(
                *modules
            )  # è¾“å‡ºå°ºå¯¸ (B, feat_dim, 1, 1)
        elif backbone == "resnet50":
            self.backbone = models.resnet50(
                weights=models.ResNet50_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.fc.in_features
            modules = list(self.backbone.children())[:-1]
            self.encoder = nn.Sequential(
                *modules
            )  # è¾“å‡ºå°ºå¯¸ (B, feat_dim, 1, 1)
        elif backbone == "efficientnet_b0":
            self.backbone = models.efficientnet_b0(
                weights=models.EfficientNet_B0_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.classifier[1].in_features

            # ç§»é™¤ EfficientNet æœ€åçš„åˆ†ç±»å™¨å±‚ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
            modules = list(self.backbone.children())[:-1]  # ç§»é™¤æœ€åçš„åˆ†ç±»å™¨å±‚
            self.encoder = nn.Sequential(*modules)
        elif backbone == "efficientnet_b1":
            self.backbone = models.efficientnet_b1(
                weights=models.EfficientNet_B1_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.classifier[1].in_features

            # ç§»é™¤ EfficientNet æœ€åçš„åˆ†ç±»å™¨å±‚ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
            modules = list(self.backbone.children())[:-1]  # ç§»é™¤æœ€åçš„åˆ†ç±»å™¨å±‚
            self.encoder = nn.Sequential(*modules)
        elif backbone == "efficientnet_b2":
            self.backbone = models.efficientnet_b2(
                weights=models.EfficientNet_B2_Weights.DEFAULT if pretrained else None
            )
            self.feat_dim = self.backbone.classifier[1].in_features

            # ç§»é™¤ EfficientNet æœ€åçš„åˆ†ç±»å™¨å±‚ï¼Œä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
            modules = list(self.backbone.children())[:-1]  # ç§»é™¤æœ€åçš„åˆ†ç±»å™¨å±‚
            self.encoder = nn.Sequential(*modules)
        else:
            raise ValueError(f"Unsupported backbone: {backbone}")

        # ---------------------
        # Projection Headï¼ˆæŠ•å½±å¤´ï¼‰
        # ---------------------
        self.proj = nn.Sequential(
            nn.Linear(self.feat_dim, self.feat_dim),
            nn.ReLU(inplace=True),
            nn.Linear(self.feat_dim, proj_dim),
        )

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼š
        """

        # Backboneè¾“å‡ºæ˜¯ (B, feat_dim, 1, 1)ï¼Œéœ€ reshape
        f = self.encoder(x).reshape(x.size(0), -1)  # -> (B, feat_dim)

        # Projection head è¾“å‡º zï¼ˆæœªå½’ä¸€åŒ–ï¼‰
        z = self.proj(f)

        # å½’ä¸€åŒ–ï¼Œé€‚é…å¯¹æ¯”å­¦ä¹ 
        z = F.normalize(z, dim=1)

        return f, z


# åˆ†ç±»å™¨æƒé‡æ˜ å°„å™¨ï¼šClassifierToProtoMapper
class ClassifierToProtoMapper(nn.Module):
    """
    å°†åˆ†ç±»å™¨æƒé‡çŸ©é˜µ Wï¼ˆK Ã— Dï¼‰
    æ˜ å°„åˆ°æŠ•å½±ç©ºé—´ out_dimï¼ˆä¸ z ç»´åº¦ä¸€è‡´ï¼‰ï¼Œå¾—åˆ°åŸå‹ C2
    """

    def __init__(self, in_dim, out_dim):
        super().__init__()

        self.map = nn.Sequential(
            nn.Linear(in_dim, out_dim),
            nn.ReLU(inplace=True),
            nn.Linear(out_dim, out_dim),
        )

    def forward(self, W):
        return F.normalize(self.map(W), dim=1)


# =========================================================
# æ¨¡å— 3ï¼šç‰¹å¾é˜Ÿåˆ— FeatureQueue + åŠ¨é‡æ›´æ–°å‡½æ•° momentum_update
# =========================================================


class FeatureQueue:
    """
    BPaCo / MoCo é£æ ¼çš„ç‰¹å¾é˜Ÿåˆ—
    """

    def __init__(self, feat_dim, queue_size, device="cuda"):
        self.queue_size = queue_size
        self.device = device

        self.feats = torch.zeros(queue_size, feat_dim, device=device)
        self.labels = -1 * torch.ones(
            queue_size, dtype=torch.long, device=device
        )  # -1 è¡¨ç¤ºæ— æ•ˆ

        self.ptr = 0
        self.full = False

    @torch.no_grad()
    def enqueue(self, feats, labels):
        B = feats.shape[0]

        if B >= self.queue_size:
            feats = feats[-self.queue_size :]
            labels = labels[-self.queue_size :]
            B = feats.shape[0]

        idx = (self.ptr + torch.arange(B, device=feats.device)) % self.queue_size

        self.feats[idx] = feats.detach()
        self.labels[idx] = labels.detach()

        self.ptr = (self.ptr + B) % self.queue_size
        if self.ptr == 0:
            self.full = True

    def get(self):
        if (not self.full) and (self.ptr == 0):
            return None, None

        if self.full:
            return self.feats, self.labels
        else:
            return self.feats[: self.ptr], self.labels[: self.ptr]


@torch.no_grad()
def momentum_update(model_k, model_q, momentum):
    """
    EMA åŠ¨é‡æ›´æ–°ï¼šÎ¸_k â† m * Î¸_k + (1 - m) * Î¸_q
    """
    for param_k, param_q in zip(model_k.parameters(), model_q.parameters()):
        param_k.data = param_k.data * momentum + param_q.data * (1.0 - momentum)


# =========================================================
# æ¨¡å— 4ï¼šBPaCo æ ¸å¿ƒæŸå¤±ï¼ˆLBPaCoï¼‰ + Logit Compensation
# =========================================================


def compute_LBPaCo(
    z_batch,
    labels_batch,
    queue: FeatureQueue,
    C1_param: nn.Parameter,
    classifier,
    mapper: ClassifierToProtoMapper,
    temperature,
    device,
):
    """
    Balanced Prototype & Contrastive Loss (ç®€åŒ–å®ç°)
    ä½¿ç”¨ä¸‰ç±»åŸå‹ï¼š
        - è·¨æ‰¹ class mean
        - å¯å­¦ä¹ ä¸­å¿ƒ C1
        - åˆ†ç±»å™¨æƒé‡æ˜ å°„å¾—åˆ°çš„ C2
    """

    B, d = z_batch.shape
    q_feats, q_labels = queue.get()

    if q_feats is None:
        A_feats = z_batch
        A_labels = labels_batch
    else:
        q_feats = q_feats.to(device)
        q_labels = q_labels.to(device)
        A_feats = torch.cat([z_batch, q_feats], dim=0)
        A_labels = torch.cat([labels_batch, q_labels], dim=0)

    K = C1_param.shape[0]
    device = z_batch.device

    # 2ï¼‰è·¨æ‰¹ç±»åˆ«å‡å€¼
    class_sums = torch.zeros(K, d, device=device)
    class_counts = torch.zeros(K, device=device)

    for k in range(K):
        mask = A_labels == k
        if mask.any():
            class_sums[k] = A_feats[mask].sum(dim=0)
            class_counts[k] = mask.sum()

    valid_mask = class_counts > 0
    class_means = torch.zeros_like(class_sums)
    if valid_mask.any():
        class_means[valid_mask] = class_sums[valid_mask] / class_counts[
            valid_mask
        ].unsqueeze(1)

    # 3ï¼‰C1 å½’ä¸€åŒ–
    C1 = F.normalize(C1_param, dim=1)

    # 4ï¼‰ä»åˆ†ç±»å™¨æå–æƒé‡ï¼Œæ˜ å°„ä¸º C2
    last_linear = None
    for m in classifier.modules():
        if isinstance(m, nn.Linear):
            last_linear = m
    if last_linear is None:
        W = torch.zeros(K, d, device=device)
    else:
        W = last_linear.weight.detach()
        if W.device != device:
            W = W.to(device)

    try:
        C2 = mapper(W)
    except Exception:
        print(f"Warning: Mapper å¤±è´¥, using random initialization: {e}")

    # 5ï¼‰è®¡ç®—ä¸æ¯ä¸€ç±»åŸå‹çš„ç›¸ä¼¼åº¦
    sims_per_class = torch.zeros(B, K, device=device)
    for j in range(K):
        reps = []
        if valid_mask[j]:
            reps.append(F.normalize(class_means[j].unsqueeze(0), dim=1))
        reps.append(C1[j].unsqueeze(0))
        reps.append(C2[j].unsqueeze(0))
        reps_cat = torch.cat(reps, dim=0)  # (m_j, d)

        sims = torch.matmul(z_batch, reps_cat.t()) / temperature
        sims_exp = torch.exp(sims)
        sims_avg = sims_exp.mean(dim=1)
        sims_per_class[:, j] = sims_avg

    numerators = sims_per_class[
        torch.arange(B, device=device), labels_batch
    ] + 1e-12
    denominators = sims_per_class.sum(dim=1) + 1e-12
    loss = -torch.log(numerators / denominators).mean()
    return loss


def cross_entropy_with_logit_compensation(logits, labels, class_freq_tensor, tau):
    """
    Logit Compensationï¼š
        logits_adj = logits - tau * log(class_freq + 1)
    ç”¨æ¥ç¼“è§£é•¿å°¾åˆ†å¸ƒä¸‹å¤šæ•°ç±»çš„ä¼˜åŠ¿
    """
    eps = 1e-12
    adjustment = tau * torch.log(
        class_freq_tensor.float().to(logits.device) + 1.0 + eps
    )
    logits_adj = logits - adjustment.unsqueeze(0)
    return F.cross_entropy(logits_adj, labels)


# =========================================================
# æ¨¡å— 5ï¼šContrastiveClassifierï¼ˆè®­ç»ƒå™¨ï¼‰
# =========================================================


class ContrastiveClassifier:
    """
    è®­ç»ƒå™¨å°è£…ç±»ï¼šåŒ…å«æ¨¡å‹ã€é˜Ÿåˆ—ã€ä¼˜åŒ–å™¨ã€è®­ç»ƒ/éªŒè¯æµç¨‹
    """

    def __init__(
        self,
        images_dir: str = "images",
        annotations_dir: str = "annotations",
        output_dir: str = "./results/fingerprint_classifier_results",
        backbone: str = "resnet50",
        out_dim=128,
        queue_size=4096,
        momentum=0.999,
        beta=2.0,
        tau=1.2,
        temperature=0.1,
        num_classes=3
    ):
        self.images_dir = images_dir
        self.annotations_dir = annotations_dir
        self.device = device
        self.run_dir = output_dir
        self.backbone = backbone
        self.out_dim = out_dim
        self.queue_size = queue_size
        self.momentum = momentum
        self.beta = beta
        self.tau = tau
        self.temperature = temperature

        self.base_output_dir = Path(output_dir)

        temp_ds = ALWAnnotationsDataset(images_dir, annotations_dir, image_size=224)
        self.num_classes = temp_ds.num_classes # åŠ¨æ€è·å–

        # 1) åˆå§‹åŒ– query / key ç¼–ç å™¨
        self.model_q = BpacoEncoder(backbone, proj_dim=out_dim, pretrained=True).to(
            self.device
        )
        self.model_k = BpacoEncoder(backbone, proj_dim=out_dim, pretrained=True).to(
            self.device
        )

        for param_q, param_k in zip(
            self.model_q.parameters(), self.model_k.parameters()
        ):
            param_k.data.copy_(param_q.data)
            param_k.requires_grad = False

        # 2) åˆ†ç±»å™¨ï¼šfeat_for_cls = concat(feat_q, feat_k)
        feat_dim = self.model_q.feat_dim
        self.classifier = nn.Sequential(
            nn.Linear(feat_dim * 2, feat_dim),
            nn.ReLU(inplace=True),
            nn.Linear(feat_dim, self.num_classes),
        ).to(self.device)

        # 3) å¯å­¦ä¹ ç±»åˆ«ä¸­å¿ƒ C1
        self.C1 = nn.Parameter(
            torch.randn(self.num_classes, out_dim, device=self.device)
        )

        # 4) åˆ†ç±»å™¨æƒé‡åˆ°åŸå‹çš„ mapperï¼ˆC2ï¼‰
        self.mapper = ClassifierToProtoMapper(
            in_dim=self.classifier[-1].in_features, out_dim=out_dim
        ).to(self.device)

        # 5) ç‰¹å¾é˜Ÿåˆ—
        self.queue = FeatureQueue(
            feat_dim=out_dim, queue_size=queue_size, device=self.device
        )

        # 6) ä¼˜åŒ–å™¨
        params = (
            list(self.model_q.parameters())
            + list(self.classifier.parameters())
            + [self.C1]
            + list(self.mapper.parameters())
        )
        self.optimizer = torch.optim.SGD(
            params, lr=0.001, momentum=0.999, weight_decay=1e-4
        )
        self.scheduler = torch.optim.lr_scheduler.StepLR(
            self.optimizer, step_size=50, gamma=0.1
        )

    def create_descriptive_output_dir(
        self,
        backbone,
        epochs=50,
        batch_size=128,
        queue_size=4096,
        momentum=0.999,
        beta=0.25,
        tau=1.2,
        temperature=0.1,
        proj_dim=128,
    ):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        folder_name = (
            f"{backbone}-E{epochs}-B{batch_size}-queue{queue_size}-"
            f"momentum{momentum}-beta{beta}-tau{tau}-temp{temperature}-"
            f"proj{proj_dim}-{timestamp}"
        )
        output_dir = self.base_output_dir / folder_name
        output_dir.mkdir(parents=True, exist_ok=True)
        return output_dir

    def run_full_training(
        self, batch_size=16, epochs=300, image_size=224, val_interval=10
    ):
        # 1) Dataset
        base_ds = ALWAnnotationsDataset(
            images_dir=self.images_dir,
            annotations_dir=self.annotations_dir,
            image_size=image_size,
        )
        train_size = int(0.8 * len(base_ds))
        val_size = len(base_ds) - train_size
        generator = torch.Generator().manual_seed(SEED)
        train_ds, val_ds = torch.utils.data.random_split(base_ds, [train_size, val_size], generator=generator)

        # 2) Dataloader
        train_loader = DataLoader(
            train_ds,
            batch_size=batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True,
        )
        val_loader = DataLoader(
            val_ds,
            batch_size=batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True,
        )

        # 3) è¾“å‡ºç›®å½•
        self.run_dir = self.create_descriptive_output_dir(
            backbone=self.backbone,
            epochs=epochs,
            batch_size=batch_size,
            queue_size=self.queue_size,
            momentum=self.momentum,
            beta=self.beta,
            tau=self.tau,
            temperature=self.temperature,
            proj_dim=self.out_dim,
        )
        print(f"\nè¾“å‡ºç›®å½•å·²åˆ›å»º: {self.run_dir}")

        # 4) ç±»åˆ«é¢‘ç‡ç»Ÿè®¡ï¼ˆé•¿å°¾è¡¥å¿ç”¨ï¼‰
        freq = torch.zeros(self.num_classes, dtype=torch.long)
        for _, _, lbl in DataLoader(train_ds, batch_size=1, shuffle=False):
            freq[lbl.item()] += 1
        print("ç±»åˆ«é¢‘ç‡ç»Ÿè®¡ class freq:", freq.tolist())

        best_f1 = 0.0

        for epoch in range(1, epochs + 1):
            t0 = datetime.now()
            avg_loss = self.train_one_epoch(
                train_loader, class_freq_tensor=freq
            )
            t1 = datetime.now()
            print(
                f"\n[Epoch {epoch}] ç”¨æ—¶ {(t1 - t0).total_seconds():.1f}s, å¹³å‡loss={avg_loss:.4f}"
            )

            if epoch % val_interval == 0:
                results = self.evaluate(val_loader)

                if results["f1"] > best_f1:
                    best_f1 = results["f1"]
                    save_dir = Path(self.run_dir)
                    save_dir.mkdir(parents=True, exist_ok=True)
                    model_save_path = save_dir / "best_bpaco_checkpoint.pth"
                    torch.save(
                        {
                            "model_q": self.model_q.state_dict(),
                            "model_k": self.model_k.state_dict(),
                            "classifier": self.classifier.state_dict(),
                            "C1": self.C1.detach().cpu(),
                            "mapper": self.mapper.state_dict(),
                        },
                        model_save_path,
                    )
                    print(
                        f"ğŸ’¾ å·²ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆF1={best_f1:.4f}ï¼‰è‡³: {model_save_path}"
                    )

        final_results = self.evaluate(val_loader)

        print("\n================ æœ€ç»ˆè¯„ä¼°ç»“æœ ================")
        print(f"æœ€ç»ˆå‡†ç¡®ç‡ Accuracy : {final_results['accuracy']:.4f}")
        print(f"æœ€ç»ˆF1-score       : {final_results['f1']:.4f}")
        print(f"æœ€ç»ˆAUC            : {final_results['auc']:.4f}")
        print(f"æœ€ç»ˆ Precision     : {final_results['precision']:.4f}")
        print(f"æœ€ç»ˆ Recall        : {final_results['recall']:.4f}")

        with open(self.run_dir / "final_results.txt", "w", encoding="utf-8") as f:
            f.write("æœ€ç»ˆè¯„ä¼°ç»“æœ:\n")
            f.write(f"å‡†ç¡®ç‡ Accuracy : {final_results['accuracy']:.4f}\n")
            f.write(f"F1-score       : {final_results['f1']:.4f}\n")
            f.write(f"AUC            : {final_results['auc']:.4f}\n")
            f.write(f"Precision      : {final_results['precision']:.4f}\n")
            f.write(f"Recall         : {final_results['recall']:.4f}\n")
        print(f"è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {self.run_dir / 'final_results.txt'}")
        print("================================================\n")

        return final_results

    def train_one_epoch(self, dataloader, class_freq_tensor):
        self.model_q.train()
        self.classifier.train()

        losses = []

        for step, (v1, v2, labels) in enumerate(dataloader):
            v1 = v1.to(self.device)
            v2 = v2.to(self.device)
            labels = labels.to(self.device)

            feat_q, z_q = self.model_q(v1)
            with torch.no_grad():
                feat_k, z_k = self.model_k(v2)

            feat_for_cls = torch.cat([feat_q, feat_k], dim=1)
            logits = self.classifier(feat_for_cls)

            self.optimizer.zero_grad()

            ce_loss = cross_entropy_with_logit_compensation(
                logits, labels, class_freq_tensor, tau=self.tau
            )
            lbpaco_loss = compute_LBPaCo(
                z_q,
                labels,
                self.queue,
                self.C1,
                self.classifier,
                self.mapper,
                temperature=self.temperature,
                device=self.device,
            )
            loss = ce_loss + self.beta * lbpaco_loss

            loss.backward()
            self.optimizer.step()

            momentum_update(self.model_k, self.model_q, self.momentum)

            with torch.no_grad():
                self.queue.enqueue(z_k, labels)

            losses.append(loss.item())

        self.scheduler.step()
        return np.mean(losses)

    def plot_confusion_matrix(self, y_true, y_pred):
        from sklearn.metrics import confusion_matrix, classification_report
        import seaborn as sns

        cm = confusion_matrix(y_true, y_pred)
        num_classes = cm.shape[0]
        
        # åŠ¨æ€ç”Ÿæˆç±»åˆ«åç§°ï¼Œæ”¯æŒ3ç±»å’Œ19ç±»
        if num_classes == 3:
            class_names = ["whorl", "loop", "arch"]
            title = "Confusion Matrix - Fingerprint 3-class"
        elif num_classes > 3:
            # å¯¹äº19ç±»æˆ–æ›´å¤šç±»åˆ«ï¼Œä½¿ç”¨æ•°å­—æ ‡è¯†
            class_names = [f"Class {i}" for i in range(num_classes)]
            title = f"Confusion Matrix - Fingerprint {num_classes}-class"
        else:
            class_names = [f"Class {i}" for i in range(num_classes)]
            title = "Confusion Matrix - Fingerprint"
        
        # å¯¹äºå¤šç±»åˆ«ï¼Œè°ƒæ•´å›¾å½¢å¤§å°
        if num_classes > 10:
            figsize = (15, 12)
        else:
            figsize = (8, 6)
        
        plt.figure(figsize=figsize)
        sns.heatmap(
            cm,
            annot=num_classes <= 10,  # åªåœ¨ç±»åˆ«æ•°é‡å°‘æ—¶æ˜¾ç¤ºæ•°å€¼
            fmt="d",
            cmap="Blues",
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={"label": "Count"},
        )
        plt.title(title, fontsize=14, fontweight="bold")
        plt.ylabel("True Label", fontsize=12)
        plt.xlabel("Predicted Label", fontsize=12)
        
        # å¯¹äºå¤šç±»åˆ«ï¼Œè°ƒæ•´æ ‡ç­¾æ—‹è½¬è§’åº¦
        if num_classes > 10:
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)

        accuracy = np.trace(cm) / np.sum(cm)
        plt.figtext(0.15, 0.02, f"Overall Accuracy: {accuracy:.4f}", fontsize=10)

        plt.tight_layout()
        save_path = os.path.join(str(self.run_dir), "confusion_matrix.png")
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.show()

        print("\n=== åˆ†ç±»æŠ¥å‘Š ===")
        # é™åˆ¶ç±»åˆ«æ•°é‡ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
        if num_classes > 20:
            print(f"ç±»åˆ«æ•°é‡è¿‡å¤š ({num_classes})ï¼Œä»…æ˜¾ç¤ºéƒ¨åˆ†è¯„ä¼°æŒ‡æ ‡")
            # åªä½¿ç”¨å‰å‡ ä¸ªå’Œåå‡ ä¸ªç±»åˆ«åç§°
            report_class_names = class_names[:5] + ["..."] + class_names[-5:]
            # ä½†å®é™…æŠ¥å‘Šè¿˜æ˜¯åŒ…å«æ‰€æœ‰ç±»åˆ«
            report = classification_report(
                y_true, y_pred, digits=4
            )
        else:
            report = classification_report(
                y_true, y_pred, target_names=class_names, digits=4
            )
        print(report)

        report_path = os.path.join(str(self.run_dir), "classification_report.txt")
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)
        print(f"åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

    def plot_roc_curve(self, y_true, y_scores):
        """
        ç»˜åˆ¶ ROC æ›²çº¿
        å‚æ•°ï¼š
            y_true  : å½¢çŠ¶ (N,) çš„çœŸå®æ ‡ç­¾ï¼ˆintï¼Œ0 ~ C-1ï¼‰
            y_scores: å½¢çŠ¶ (N, num_classes) çš„ç±»åˆ«æ¦‚ç‡çŸ©é˜µ
        è¯´æ˜ï¼š
            - äºŒåˆ†ç±»ï¼šæ­£å¸¸ ROC æ›²çº¿
            - å¤šåˆ†ç±»ï¼ˆ3 ç±» / 19 ç±»ï¼‰ï¼šç”» micro-average ROC
        """
        from sklearn.metrics import roc_curve, roc_auc_score
        from sklearn.preprocessing import label_binarize

        y_true = np.array(y_true)
        y_scores = np.array(y_scores)
        num_classes = self.num_classes

        plt.figure(figsize=(8, 6))

        if num_classes == 2:
            # äºŒåˆ†ç±»ï¼šç›´æ¥ç”¨æ­£ç±»æ¦‚ç‡
            fpr, tpr, _ = roc_curve(y_true, y_scores[:, 1])
            auc_score = roc_auc_score(y_true, y_scores[:, 1])
            plt.plot(fpr, tpr, label=f"ROC curve (AUC = {auc_score:.3f})")
        else:
            # å¤šåˆ†ç±»ï¼šmicro-average ROC
            y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))
            fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_scores.ravel())
            auc_score = roc_auc_score(
                y_true_bin,
                y_scores,
                multi_class="ovr",
                average="micro",
            )
            plt.plot(
                fpr,
                tpr,
                label=f"Micro-average ROC (AUC = {auc_score:.3f})",
            )

        # å¯¹è§’çº¿ï¼ˆéšæœºåˆ†ç±»å™¨ï¼‰
        plt.plot([0, 1], [0, 1], "k--", label="Random")

        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title("ROC Curve")
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)

        roc_path = os.path.join(str(self.run_dir), "roc_curve.png")
        plt.tight_layout()
        plt.savefig(roc_path, dpi=300, bbox_inches="tight")
        print(f"ROC æ›²çº¿å·²ä¿å­˜è‡³: {roc_path}")
        plt.close()



    @torch.no_grad()
    def evaluate(self, dataloader):
        """
        åœ¨éªŒè¯é›†æˆ–æµ‹è¯•é›†ä¸Šè¯„ä¼°å½“å‰æ¨¡å‹æ€§èƒ½
        - å¯¹ä»»æ„ç±»åˆ«æ•° self.num_classes å‡é€‚ç”¨ï¼ˆ3 ç±» / 19 ç±»ï¼‰
        - AUC ä½¿ç”¨å¤šç±»åˆ«è®¾ç½®ï¼š
            * äºŒåˆ†ç±»æ—¶ï¼šç›´æ¥ç”¨æ­£ç±»æ¦‚ç‡
            * å¤šåˆ†ç±»æ—¶ï¼šä½¿ç”¨ one-vs-rest çš„ micro-average AUC
        """
        self.model_q.eval()
        self.classifier.eval()

        y_true = []
        y_pred = []
        prob_list = []   # æ¯ä¸ªæ ·æœ¬çš„å®Œæ•´ç±»åˆ«æ¦‚ç‡å‘é‡

        for v1, v2, labels in dataloader:
            v1 = v1.to(self.device)
            v2 = v2.to(self.device)
            labels = labels.to(self.device)

            # å‰å‘ï¼ˆquery + keyï¼‰
            feat_q, _ = self.model_q(v1)
            feat_k, _ = self.model_k(v2)
            feat_for_cls = torch.cat([feat_q, feat_k], dim=1)
            logits = self.classifier(feat_for_cls)

            probs = torch.softmax(logits, dim=1)   # (B, num_classes)
            preds = probs.argmax(dim=1)

            y_true.extend(labels.cpu().numpy().tolist())
            y_pred.extend(preds.cpu().numpy().tolist())
            prob_list.append(probs.cpu().numpy())

        # åˆå¹¶æ‰€æœ‰ batch çš„æ¦‚ç‡
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_scores = np.concatenate(prob_list, axis=0)   # (N, num_classes)

        # --------- å„ç§æŒ‡æ ‡ ----------
        num_classes = self.num_classes

        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average="macro")
        prec = precision_score(y_true, y_pred, average="macro", zero_division=0)
        rec = recall_score(y_true, y_pred, average="macro", zero_division=0)

        # AUCï¼š
        try:
            if num_classes == 2:
                # äºŒåˆ†ç±»ï¼šå–æ­£ç±»ï¼ˆ1ï¼‰æ¦‚ç‡
                auc = roc_auc_score(y_true, y_scores[:, 1])
            else:
                # å¤šåˆ†ç±»ï¼šä½¿ç”¨ one-vs-rest çš„ micro-average AUC
                from sklearn.preprocessing import label_binarize

                y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))
                auc = roc_auc_score(
                    y_true_bin,
                    y_scores,
                    multi_class="ovr",
                    average="micro",
                )
        except Exception:
            print("AUC è®¡ç®—å¤±è´¥")
            auc = 0.0

        # æ··æ·†çŸ©é˜µ & ROC æ›²çº¿
        self.plot_confusion_matrix(y_true.tolist(), y_pred.tolist())
        self.plot_roc_curve(y_true, y_scores)

        return {
            "accuracy": float(acc),
            "f1": float(f1),
            "auc": float(auc),
            "precision": float(prec),
            "recall": float(rec),
            "y_true": y_true.tolist(),
            "y_pred": y_pred.tolist(),
        }



# =========================================================
# æ¨¡å— 6ï¼šä¸»ç¨‹åº main()
# =========================================================


def main():
    output_dir = "./results/fingerprint_bpaco_3cls_results"

    model = ContrastiveClassifier(
        images_dir="images",
        annotations_dir="annotations",
        output_dir=output_dir,
        backbone="resnet50",
        out_dim=128,
        queue_size=4096,
        momentum=0.999,
        beta=1.5, # BPaCo æŸå¤±çš„æƒé‡ç³»æ•°,beta å¤§ â†’ æ›´é‡è§†å¯¹æ¯”å­¦ä¹ ;beta å° â†’ æ›´é‡è§†åˆ†ç±»å™¨ CEã€‚ é•¿å°¾æ•ˆåº”ä¸¥é‡å°±å¢å¤§(0.5 ï½ 2.0)
        tau=1.2,
        temperature=0.1,
    )
    model.run_full_training(
        batch_size=128,
        epochs=100,
        image_size=224,
        val_interval=10,
    )


if __name__ == "__main__":
    main()
